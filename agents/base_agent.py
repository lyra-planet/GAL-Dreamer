"""
AgentåŸºç±»
æ‰€æœ‰Agentçš„çˆ¶ç±»
"""
import json
from typing import Any, Dict, List
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.messages import HumanMessage, SystemMessage
from utils.config import config
from utils.logger import log
from utils.json_utils import safe_parse_json


# JSONä¿®å¤æç¤ºè¯æ¨¡æ¿
JSON_FIX_PROMPT = """ä½ ä¹‹å‰ç”Ÿæˆçš„JSONæ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·ä¿®å¤ã€‚

ã€é”™è¯¯ä¿¡æ¯ã€‘
{error_message}

ã€ä½ ä¹‹å‰ç”Ÿæˆçš„JSONã€‘
{previous_json}

ã€è¦æ±‚ã€‘
1. å¿…é¡»è¿”å›å®Œæ•´çš„JSONæ ¼å¼
2. å¿…é¡»åŒ…å«ä»¥ä¸‹å¿…å¡«å­—æ®µ: {required_fields}
3. ä¸è¦è¾“å‡ºä»»ä½•JSONä¹‹å¤–çš„è§£é‡Šæ–‡å­—
4. ç›´æ¥è¾“å‡ºä¿®å¤åçš„JSON

è¯·é‡æ–°ç”Ÿæˆæ­£ç¡®çš„JSON:
"""


class BaseAgent:
    """AgentåŸºç±»"""

    def __init__(self, name: str, system_prompt: str, human_prompt_template: str, use_structured_output: bool = True):
        """
        åˆå§‹åŒ–Agent

        Args:
            name: Agentåç§°
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            human_prompt_template: äººç±»æç¤ºè¯æ¨¡æ¿
            use_structured_output: æ˜¯å¦ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º(é»˜è®¤True)
        """
        self.name = name
        self.system_prompt = system_prompt
        self.human_prompt_template = human_prompt_template
        self.use_structured_output = use_structured_output

        # åˆå§‹åŒ–LLMé…ç½®
        if self.use_structured_output:
            # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºæ—¶,éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡æˆ–ç›´æ¥åœ¨client_kwargsä¸­ä¼ é€’
            self.llm = ChatOpenAI(
                model=config.LLM_MODEL,
                api_key=config.LLM_API_KEY,
                base_url=config.LLM_BASE_URL,
                temperature=config.LLM_TEMPERATURE,
                max_tokens=config.LLM_MAX_TOKENS,
                timeout=config.LLM_TIMEOUT,
                model_kwargs={
                    "response_format": {"type": "json_object"}
                }
            )
            log.info(f"{self.name} å¯ç”¨ç»“æ„åŒ–è¾“å‡º")
        else:
            self.llm = ChatOpenAI(
                model=config.LLM_MODEL,
                api_key=config.LLM_API_KEY,
                base_url=config.LLM_BASE_URL,
                temperature=config.LLM_TEMPERATURE,
                max_tokens=config.LLM_MAX_TOKENS,
                timeout=config.LLM_TIMEOUT,
            )

        # åˆ›å»ºJSONè¾“å‡ºè§£æå™¨
        self.parser = JsonOutputParser()

        # æœ€å¤§ä¿®å¤è½®æ•° (åŒ…æ‹¬åˆæ¬¡ç”Ÿæˆ)
        self.max_fix_rounds = 4

        log.info(f"{self.name} åˆå§‹åŒ–å®Œæˆ")

    def _create_prompt(self) -> ChatPromptTemplate:
        """
        åˆ›å»ºå®Œæ•´çš„promptæ¨¡æ¿ï¼ˆä¸è¿›è¡Œå˜é‡æ›¿æ¢ï¼‰

        Returns:
            ChatPromptTemplateå®ä¾‹
        """
        prompt = ChatPromptTemplate.from_messages([
            ("system", self.system_prompt),
            ("human", self.human_prompt_template)
        ])

        return prompt

    def _extract_json(self, response: str) -> Dict[str, Any]:
        """
        ä»å“åº”ä¸­æå–JSON

        Args:
            response: LLMçš„å“åº”æ–‡æœ¬

        Returns:
            è§£æåçš„JSONå­—å…¸
        """
        try:
            # ä½¿ç”¨å®‰å…¨è§£æå‡½æ•°
            result = safe_parse_json(response.strip())

            if not result:
                # å°è¯•æå–JSONéƒ¨åˆ†(å¤„ç†å¯èƒ½çš„å¤šä½™æ–‡æœ¬)
                start = response.find("{")
                end = response.rfind("}")

                if start != -1 and end != -1 and end > start:
                    json_str = response[start:end + 1]
                    result = safe_parse_json(json_str)

            if result:
                log.debug(f"æˆåŠŸæå–JSON: {str(result)[:100]}...")
                return result
            else:
                raise ValueError(f"å“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚åŸå§‹å“åº”: {response}")

        except Exception as e:
            log.error(f"{self.name} JSONè§£æå¤±è´¥: {e}")
            log.error(f"åŸå§‹å“åº”: {response}")
            raise

    def _get_required_fields(self) -> List[str]:
        """
        è·å–å½“å‰Agentè¦æ±‚çš„å¿…å¡«å­—æ®µåˆ—è¡¨
        å­ç±»åº”è¯¥é‡å†™æ­¤æ–¹æ³•è¿”å›å…¶å¿…å¡«å­—æ®µ

        Returns:
            å¿…å¡«å­—æ®µåˆ—è¡¨
        """
        return []

    def _fix_json_output(self, previous_json: Dict[str, Any], error_message: str) -> Dict[str, Any]:
        """
        è®©LLMä¿®å¤ä¸æ­£ç¡®çš„JSONè¾“å‡º

        Args:
            previous_json: ä¹‹å‰ç”Ÿæˆçš„JSON
            error_message: éªŒè¯é”™è¯¯ä¿¡æ¯

        Returns:
            ä¿®å¤åçš„JSON
        """
        required_fields = self._get_required_fields()
        required_fields_str = ", ".join(required_fields) if required_fields else "æ‰€æœ‰åŸå§‹å­—æ®µ"

        # æ„å»ºä¿®å¤æç¤º
        fix_prompt = JSON_FIX_PROMPT.format(
            error_message=error_message,
            previous_json=json.dumps(previous_json, ensure_ascii=False, indent=2),
            required_fields=required_fields_str
        )

        # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºè°ƒç”¨ä¿®å¤
        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=fix_prompt)
        ]

        try:
            response = self.llm.invoke(messages)
            fixed_json = self._extract_json(response.content)
            log.info(f"{self.name} JSONä¿®å¤å°è¯•æˆåŠŸ")
            return fixed_json
        except Exception as e:
            log.error(f"{self.name} JSONä¿®å¤å¤±è´¥: {e}")
            # è¿”å›åŸå§‹JSONï¼Œè®©å¤–å±‚ç»§ç»­é‡è¯•
            return previous_json

    def run(self, **kwargs) -> Dict[str, Any]:
        """
        è¿è¡ŒAgent,å¸¦JSONéªŒè¯å’Œä¿®å¤é‡è¯•æœºåˆ¶

        Args:
            **kwargs: è¾“å…¥å‚æ•°

        Returns:
            Agentè¾“å‡ºçš„JSONå­—å…¸
        """
        log.info(f"{self.name} å¼€å§‹æ‰§è¡Œ...")

        # åˆ›å»ºpromptæ¨¡æ¿
        prompt_template = self._create_prompt()

        # æ„å»ºé“¾
        chain = prompt_template | self.llm

        current_result = None
        last_error = None

        # å¤šè½®ä¿®å¤æœºåˆ¶: 1æ¬¡åˆå§‹ç”Ÿæˆ + 3æ¬¡ä¿®å¤ = 4è½®
        for round_num in range(self.max_fix_rounds):
            try:
                if round_num == 0:
                    # ç¬¬ä¸€è½®: æ­£å¸¸ç”Ÿæˆ
                    log.info(f"{self.name} ç¬¬{round_num + 1}è½®: ç”Ÿæˆä¸­...")
                    response = chain.invoke(kwargs)
                    response_text = response.content
                else:
                    # åç»­è½®: ä¿®å¤æ¨¡å¼
                    log.info(f"{self.name} ç¬¬{round_num + 1}è½®: ä¿®å¤ä¸­...")
                    response_text = self._fix_json_output(
                        previous_json=current_result,
                        error_message=last_error
                    )
                    # fix_json_output å·²ç»è¿”å›è§£æåçš„dict
                    if isinstance(response_text, dict):
                        response_text = json.dumps(response_text, ensure_ascii=False)

                log.info(f"{self.name} LLMåŸå§‹å“åº”:")
                log.info(f"{response_text}")
                log.info(f"{'='*60}")

                # æå–JSON
                result = self._extract_json(response_text)
                current_result = result

                # éªŒè¯è¾“å‡º
                validation_result = self.validate_output(result)

                if validation_result is True:
                    # éªŒè¯é€šè¿‡
                    log.success(f"{self.name} æ‰§è¡ŒæˆåŠŸ (ç¬¬{round_num + 1}è½®)")
                    return result
                elif isinstance(validation_result, str):
                    # éªŒè¯å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                    last_error = validation_result
                    log.warning(f"{self.name} éªŒè¯å¤±è´¥: {validation_result}")
                    # ç»§ç»­ä¸‹ä¸€è½®ä¿®å¤
                else:
                    # éªŒè¯å¤±è´¥ï¼Œæ²¡æœ‰å…·ä½“é”™è¯¯ä¿¡æ¯
                    last_error = "æ ¼å¼éªŒè¯å¤±è´¥ï¼Œç¼ºå°‘å¿…å¡«å­—æ®µæˆ–æ ¼å¼ä¸æ­£ç¡®"
                    log.warning(f"{self.name} éªŒè¯å¤±è´¥ï¼Œå°†å°è¯•ä¿®å¤")

            except Exception as e:
                error_msg = str(e)

                # æ£€æŸ¥æ˜¯å¦æ˜¯å†…å®¹å®¡æ ¸é”™è¯¯
                if "data_inspection_failed" in error_msg or "inappropriate content" in error_msg.lower():
                    log.warning(f"{self.name} å†…å®¹å®¡æ ¸å¤±è´¥ (ç¬¬{round_num + 1}è½®)")
                    if round_num < self.max_fix_rounds - 1:
                        import time
                        time.sleep(1)
                        continue
                    else:
                        log.error(f"{self.name} å†…å®¹å®¡æ ¸å¤±è´¥,å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
                        return self._get_fallback_response()
                else:
                    last_error = f"æ‰§è¡Œé”™è¯¯: {error_msg}"
                    log.error(f"{self.name} æ‰§è¡Œå¤±è´¥: {e}")
                    # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­
                    if round_num < self.max_fix_rounds - 1:
                        continue
                    else:
                        raise

        # æ‰€æœ‰è½®æ¬¡éƒ½å¤±è´¥ï¼Œè¿”å›fallback
        log.error(f"{self.name} å·²è¾¾æœ€å¤§ä¿®å¤è½®æ•°({self.max_fix_rounds}),è¿”å›fallback")
        return self._get_fallback_response()

    def _get_fallback_response(self) -> Dict[str, Any]:
        """
        å½“Agentå¤±è´¥æ—¶è¿”å›å®‰å…¨é»˜è®¤å€¼
        å­ç±»å¯ä»¥é‡å†™æ­¤æ–¹æ³•æä¾›ç‰¹å®šé»˜è®¤å€¼
        """
        return {
            "error": "Agent execution failed after max retries",
            "fallback": True
        }

    def validate_output(self, output: Dict[str, Any]) -> bool:
        """
        éªŒè¯è¾“å‡ºæ˜¯å¦æœ‰æ•ˆ

        Args:
            output: Agentè¾“å‡º

        Returns:
            True: éªŒè¯é€šè¿‡
            str: éªŒè¯å¤±è´¥çš„é”™è¯¯ä¿¡æ¯
            bool: Falseè¡¨ç¤ºéªŒè¯å¤±è´¥(æ— å…·ä½“ä¿¡æ¯)
        """
        # å­ç±»å¿…é¡»é‡å†™æ­¤æ–¹æ³•
        # è¿”å› True è¡¨ç¤ºéªŒè¯é€šè¿‡
        # è¿”å› str è¡¨ç¤ºéªŒè¯å¤±è´¥ï¼Œè¿”å›é”™è¯¯æè¿°
        required_fields = self._get_required_fields()
        missing_fields = [f for f in required_fields if f not in output]

        if missing_fields:
            return f"ç¼ºå°‘å¿…å¡«å­—æ®µ: {', '.join(missing_fields)}"

        return True

    def redo_with_feedback(self, previous_output: Dict[str, Any], feedback_issues: List[Any], original_kwargs: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ ¹æ®ä¸€è‡´æ€§å®¡æŸ¥åé¦ˆé‡åšç”Ÿæˆ

        Args:
            previous_output: ä¹‹å‰çš„è¾“å‡ºç»“æœ
            feedback_issues: ConsistencyIssue åˆ—è¡¨ï¼ŒåŒ…å«å…·ä½“é—®é¢˜å’Œä¿®å¤å»ºè®®
            original_kwargs: åŸå§‹è¾“å…¥å‚æ•°

        Returns:
            ä¿®å¤åçš„è¾“å‡º
        """
        log.info(f"{self.name} æ ¹æ®åé¦ˆé‡åšï¼Œé—®é¢˜æ•°: {len(feedback_issues)}")

        # æ„å»ºåé¦ˆæç¤º
        feedback_prompt = self._build_feedback_prompt(previous_output, feedback_issues)

        # ä½¿ç”¨åé¦ˆæç¤ºè°ƒç”¨ LLM
        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=feedback_prompt)
        ]

        max_redo_rounds = 2
        for round_num in range(max_redo_rounds):
            try:
                log.info(f"{self.name} é‡åšç¬¬{round_num + 1}è½®...")

                response = self.llm.invoke(messages)
                result = self._extract_json(response.content)

                log.info(f"{self.name} é‡åšå“åº”:")
                log.info(f"{json.dumps(result, ensure_ascii=False, indent=2)[:500]}...")

                # éªŒè¯é‡åšç»“æœ
                validation_result = self.validate_output(result)
                if validation_result is True:
                    log.success(f"{self.name} é‡åšæˆåŠŸ!")
                    return result
                else:
                    log.warning(f"{self.name} é‡åšéªŒè¯å¤±è´¥: {validation_result}")
                    # æ›´æ–° messages è®© LLM ç»§ç»­ä¿®å¤
                    messages.append(SystemMessage(content=f"ä½ ä¹‹å‰çš„è¾“å‡ºä»æœ‰é—®é¢˜: {validation_result}ã€‚è¯·é‡æ–°ä¿®å¤ã€‚"))
                    continue

            except Exception as e:
                log.error(f"{self.name} é‡åšå¤±è´¥: {e}")
                if round_num < max_redo_rounds - 1:
                    continue
                else:
                    # é‡åšå¤±è´¥ï¼Œè¿”å›åŸå§‹ç»“æœ
                    log.warning(f"{self.name} é‡åšå¤±è´¥ï¼Œè¿”å›åŸå§‹ç»“æœ")
                    return previous_output

        return previous_output

    def _build_feedback_prompt(self, previous_output: Dict[str, Any], feedback_issues: List[Any]) -> str:
        """
        æ„å»ºåé¦ˆæç¤ºè¯

        Args:
            previous_output: ä¹‹å‰çš„è¾“å‡º
            feedback_issues: åé¦ˆé—®é¢˜åˆ—è¡¨

        Returns:
            åé¦ˆæç¤ºè¯
        """
        # è¿‡æ»¤å‡ºé’ˆå¯¹å½“å‰ Agent çš„é—®é¢˜
        my_issues = [issue for issue in feedback_issues
                     if hasattr(issue, 'source_agent') and issue.source_agent == self.name]

        if not my_issues:
            # å¦‚æœæ²¡æœ‰é’ˆå¯¹å½“å‰ Agent çš„é—®é¢˜ï¼Œå¯èƒ½æ˜¯é€šç”¨é—®é¢˜
            my_issues = feedback_issues

        prompt_parts = [
            "ä¸€è‡´æ€§å®¡æŸ¥å‘ç°äº†ä»¥ä¸‹é—®é¢˜ï¼Œè¯·ä½ æ ¹æ®åé¦ˆä¿®æ”¹ä¹‹å‰çš„è¾“å‡ºï¼š",
            "",
            "ã€ä¹‹å‰çš„è¾“å‡ºã€‘",
            json.dumps(previous_output, ensure_ascii=False, indent=2),
            "",
            "ã€å‘ç°çš„é—®é¢˜ã€‘"
        ]

        for issue in my_issues:
            severity_icon = {
                "low": "ğŸŸ¢",
                "medium": "ğŸŸ¡",
                "high": "ğŸŸ ",
                "critical": "ğŸ”´"
            }.get(getattr(issue, 'severity', 'medium'), "âšª")

            issue_desc = f"{severity_icon} ä¸¥é‡ç¨‹åº¦: {getattr(issue, 'severity', 'medium')}"
            issue_desc += f"\n   é—®é¢˜: {getattr(issue, 'description', 'æœªçŸ¥é—®é¢˜')}"
            issue_desc += f"\n   ä¿®å¤å»ºè®®: {getattr(issue, 'fix_suggestion', 'æ— ')}"

            if hasattr(issue, 'related_field') and issue.related_field:
                issue_desc += f"\n   ç›¸å…³å­—æ®µ: {issue.related_field}"

            prompt_parts.append(issue_desc)

        prompt_parts.extend([
            "",
            "ã€è¦æ±‚ã€‘",
            "1. ä¿æŒä¸åŸè¾“å‡ºä¸€è‡´çš„ç»“æ„",
            "2. åªä¿®æ”¹æœ‰é—®é¢˜çš„éƒ¨åˆ†",
            "3. ç¡®ä¿ä¿®æ”¹åä¸å†è¿åä¹‹å‰çš„è®¾å®š",
            "4. è¾“å‡ºå®Œæ•´çš„JSONæ ¼å¼",
            "",
            "è¯·è¾“å‡ºä¿®å¤åçš„JSON:"
        ])

        return "\n".join(prompt_parts)
